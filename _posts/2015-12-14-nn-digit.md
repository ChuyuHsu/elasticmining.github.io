---
layout: post
title: Let's Play with Neural Network - Part 2
categories: neural network
description: "Once we've done in preparation for basic algorithm, applying the coding to a classification problem is easy. This article shows a simple workflow for building a digit recognizer for the kaggle project."
comments: true
tags: [neural network, kaggle, machine learning, matlab, octave]
image:
  feature:
  credit: 
  creditlink: 
date: 2015-12-07T00:00:00+00:00
author: ryanchao
---


### **Let's Play with Neural Network - Part 2**

#### **Multi-Classifier: Digit Recognizer**

* [Let's Play with Neural Network - Part 1](http://www.elasticmining.com/post/2015-12-07/nn-basic.html)
* **Let's Play with Neural Network - Part 2**

While the basic coding for neural network(NN) is ready, we could try to build a simple hypothesis for multi-class classification, a recognizer for classifying hand-written digits is a good topic for practicing. Let's kick off this demo from ["Getting Started Project: Digit Recognizer"](https://www.kaggle.com/c/digit-recognizer) on the kaggle community.
<div style="text-align:center" markdown="1">
![digit recognizer](/img/posts/front_page.png)
</div>


Our goal is clear: giving a grayscale image with 28x28 pixels, identify the digit the picture shows from '0' to '9'. Concretely, our raw features are the grayscale values at every pixel, with those values, NN attempts to figure out the relationship between pixels, and learning the stroke patterns from different digits, via the supervised learning process, NN could find out the most probable digit the pixels formed. These could be summarized in two facts: (1) the size of the feature space(input layer size) is equal to 784 since all grayscale values may vary independently, (2) we need 10 labels(output layer size) to indicate the digits from '0' to '9'.

After specifying the parameters, initializing a NN model by this script:

```matlab
function [theta_list layer_size] = create_model(input_size, label_size, hidden_size)
	
	theta_num = length(hidden_size) + 1;
	layer_size = zeros(theta_num + 1, 1);
	layer_size(1) = input_size;
	for j = 2 : length(layer_size) - 1
		layer_size(j) = hidden_size(j - 1);
	end
	layer_size(end) = label_size;

	theta_list = cell(theta_num, 1);
	for i = 1 : theta_num
		theta_list{i} = 1 * (rand(layer_size(i+1), layer_size(i) + 1) - rand(layer_size(i+1), layer_size(i) + 1));
	end

	save -binary 'model/model_v0.nn' theta_list layer_size

end

```

Meanings of the arguments:

> *input_size*: size of the input layer, 784 units for this demo.
> *label_size*: number of the labels, or size of the output layer, 10 units for this demo.
> *hidden_size*: size of each hidden layer, it could be a vector as there might be more than one hidden layer.
> *theta_list*: a cell array stores every matrix $\Theta^{(i)}$ for function mapping between layers.
> *layer_size*: store the sizes of all layers for computational convenience.

To ensure the gradient decent works properly, we have to avoid symmetry problem[^1] by randomly initializing all the weight's values, then assume we have only one hidden layer with size: 100 units, simply type the following command to build our NN model.

````
octave:1> [theta_list layer_size] = create_model(784, 10, 100);
````

The training data contained in *train.csv* could be downloaded from kaggle, after extracting the total 42,000 samples, we organized the training-set in matrices format as below in order to feed NN efficiently:

$$ \begin{align*} 
& Training\ set : 
X = 
\begin{Bmatrix}
-x^{(1)}- \\
-x^{(2)}- \\
. \\
. \\
-x^{(42000)}- \\
\end{Bmatrix}
,\ Y =
\begin{Bmatrix}
-y^{(1)}- \\
-y^{(2)}- \\
. \\
. \\
-y^{(42000)}- \\
\end{Bmatrix} \\ \\
\end{align*}$$ 

> $-x^{(i)}-$: represent the 784 grayscale values of sample $i$ as a row vector.
> $-y^{(i)}-$: represent the label of sample $i$ as a row vector, fill the corresponding entry with '1' and leaving else entries '0'. 
> For instance:
> $[-y^{(i)}-] = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\quad with\ label=3$
> or
> $[-y^{(i)}-] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\quad with\ label=10$


Finally, it's time for machine learning! Import our NN model and training set we just built, then apply 'mini-batch' gradient descent method[^2] which is used to find the optimum, the implementation is showed below, and the summarized workflow:
1. Before each training cycle, shuffle the training set, and extracting a subset with a defined batch size.
2. Divide the subset with a ratio into two groups, one for mini-batch training, one for validation process.
3. Normalize the grayscale values from [0, 255] to [0, 1].
4. Transform the label numbers into 1/0 matrix representation.
5. Feed $Xtrain$ and $Ytrain$ into optimizer and performing supervised learning.
6. The hypothesis get improved little by little after each iteration.
7. After a training cycle, we calculate the error rates to measure the performance.

```matlab
load 'model/model_v0.nn';
load 'data_frame/train.df';

sample_num = rows(train.X);
lambda = 0.1;
opt = optimset('MaxIter', 10);
batch_size = 5000;
valid_ratio = 0.3;
thl = theta_list;

for i = 1 : 10
	batch_idx = randperm(sample_num)(1 : batch_size);
	training_num = round(length(batch_idx) * (1 - valid_ratio));
	validation_num = batch_size - training_num;

	Xtrain = double(train.X(batch_idx(1 : training_num), :)) / 255.0;
	Yt = double(train.Y(batch_idx(1 : training_num), :));
	Ytrain = zeros(10, training_num);
	Ytrain([Yt + [0 : 10 : 10*(training_num - 1)](:)]) = 1;
	Ytrain = Ytrain';

	Xval = double(train.X(batch_idx(training_num + 1 : end), :)) / 255.0;
	Yv = double(train.Y(batch_idx(training_num + 1 : end), :));
	Yval = zeros(10, validation_num);
	Yval([Yv + [0 : 10 : 10*(validation_num - 1)](:)]) = 1;
	Yval = Yval';

	func = @(p) cost_function(p, layer_size, Xtrain, Ytrain, lambda);

	[thv cost] = fmincg(func, list_to_vector(thl), opt);
	thl = vector_to_list(thv, layer_size);

	printf('===== %d =====\n', i);
	O = nn_forward(thl, Xtrain);

	er_tr = error_rate(O, Yt);
	fprintf('  Training error: \n');
	fprintf('  %1.3f \n', er_tr);

	O = nn_forward(thl, Xval);

	er_val = error_rate(O, Yv);
	fprintf('  Validation error: \n');
	fprintf('  %1.3f \n', er_val);
	printf('\n');

	theta_list = thl;
	er = [er [er_tr ; er_val]];

end

```

Since NN can easily build high complexity model, the overfitting issue may occur, when the training error decreases steadily, the validation error may increase instead. To monitor  this problem, we check whether these errors are still met after every training cycle, we can also tune the regularization parameter: *lambda* to suppress overfitting.

After a few iterations, our NN model converged around a local minimum, we paused the training process and took this model as our first digit recognizer, then applied to the test set, finally submitted the results back to kaggle, and this is what we got: accuracy around 97.143% with ranking at #381. Our NN model did a good prediction although there is still room for improvement, well, don't worry, we'll be back to discuss this topic later.

![leaderboard result](/img/posts/first_submit.png)




#### **REFERENCE** 
[^1]: [Symmetry breaking](http://stackoverflow.com/questions/20027598/why-should-weights-of-neural-networks-be-initialized-to-random-numbers)
[^2]: [Mini-batch gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)