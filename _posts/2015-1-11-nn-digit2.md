---
layout: post
title: Let's Play with Neural Network - Part 3
categories: neural network
description: "After preliminary mining and building models, the accuracy of the digit recognizer seems to get stuck. In this post, we share some simple tricks to improve the performance."
comments: true
tags: [neural network, kaggle, machine learning, matlab, octave]
image:
feature:
credit: 
creditlink: 
date: 2016-1-13T00:00:00+00:00
author: ryanchao
---

### **Let's Play with Neural Network - Part 3**

#### **Impove Our Digit Recognizer**

* [Let's Play with Neural Network - Part 1](http://www.elasticmining.com/post/2015-12-07/nn-basic.html)
* [Let's Play with Neural Network - Part 2](http://www.elasticmining.com/post/2015-12-17/nn-digit.html)
* **Let's Play with Neural Network - Part 3**

Last time we swiftly built a nice model to recognize handwritten digits, and we have seen the power of "vanilla neural network" with only one hidden layer. It easily achieved high accuracy around 97% on kaggle leaderboard in our first try, can we do better? And is there any way to improve our model? The real challenge has just begun, in this post, I want to share some tricks that might help.

Before we started to do some feature engineering, it's a good idea to take a look at the model we have trained already, we knew NN could extract patterns and store the features in the weight matrices, to understand how did NN work, we visualized the weights to get more sense. The following images show 12 different features NN learned, each image has different lightness/darkness distributions around the center, since all digit samples are center-aligned, leaving very few information at the border region, it looks void there in these images, that would imply our model spent a certain part of efforts on training nothing, which may cause issues such as wasting unnecessary time on computation, introducing unwanted noises, misleading the optimization process and so on. If we have our raw samples more clean and remove the redundant information, we could expect the NN can do better.
<div style="text-align:center" markdown="1">
![nn features](/img/blog/ryan/nn_features.png)
</div>

Back to these images, what do those grays mean? As an analogy, we can imagine these patterns are some kind of "opacity masks" with the same dimensions of the raw samples, the lightness means "transparency", what NN tried to do was: it covered raw samples with every mask, under the mask some parts of the digits(such as edges) were exposed in the bright region, each mask was connected to an perceptron, and the perceptron calculated how many pixels of the digit can be seen through the mask. If NN have 100 perceptrons in the hidden layer, that means there are 100 masks to detect different shapes of edges. From training data, we expect the most digits with same label would have similar shapes, therefore NN can perform a good prediction, but there are still some look quite different after the mask filtering, that might be the cause of restricting the performance of the model.
<div style="text-align:center" markdown="1">
![sample1](/img/blog/ryan/sample4.png)

*The digit "4" samples with diffent styles.*
</div>

After inspecting the training set, we found some digits were in **bold** or *italics* styles, or maybe just a ugly writing with a random rotation. If we could determine the declination of the hand-written style, and rotate it back to a standard direction, the deviation between digits should be suppressed. To find the angle we needed, we first divided the raw image into several strip zones, since the image was 28x28, we got 28 strips at most, and calculated the geometry centers in each strip, then we got a small data set that recorded every coordinates of the centers, finally we used a straight line to fit this data set, by the slope of the line we determined the angle. Another deviation we wanted to eliminate was the size of the digits. You may notice that some digits should be thin such as "1", and some should be fat just like "8", but it's common to find bold "1"s or slim "8"s in training set, and NN would easily go wrong on those samples, however after the rotation normalization, we could expect most of the digits get better and similar orientations, that could help us find correct rectangulars to align every image and rescaling it to the size we wanted, we could use smaller image dimensions instead of the raw 28x28, the computation efficiency should increase while the geometry features could still be retained. Moreover, this process also remove the "blank" regions which almost have no contribution for training.
<div style="text-align:center" markdown="1">
![sample4](/img/blog/ryan/sample4_angle2.png)
![sample1_8](/img/blog/ryan/sample1_8.png)
</div>

One another simple trick you can try with NN is aggregation, this method is often used in machine learning to improve the stability and preventing the model from overfitting, and there are many alternative versions to implement it. Since every NN is initialized randomly, the different initial states would lead the optimizer converged toward different directions, result the model end up with diverse performance and weakness. A simple idea is to aggregate all predictions from every model, then output the "voting results", it's also called "uniform blending" method. In this project so far, we use about 10 NNs to perform aggregation, each NN has 400 units at input layer(the images' sizes were downgraded from 28x28 to 20x20) and two hidden layers both got 100 perceptrons, finally the accuracy was improved around 98.4%, and we would keep trying.
<div style="text-align:center" markdown="1">
![sample4](/img/blog/ryan/second_milestone.png)
</div>
So do you have any tricks? share with us!




